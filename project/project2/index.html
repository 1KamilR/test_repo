<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Kamil Riaz" />
    
    <link rel="shortcut icon" type="image/x-icon" href="/img/favicon.ico">
    <title>Project 2: Modeling, Testing, and Predicting</title>
    <meta name="generator" content="Hugo 0.79.0" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="/css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">
      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="/"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="/post/">BLOG</a></li>
        
        <li><a href="/projects/">PROJECTS</a></li>
        
        <li><a href="/resume/">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="/project/project2/">Project 2: Modeling, Testing, and Predicting</a></strong>
          </h3>
        </div>
 
<div class="blog-title">
          <h4>
         January 1, 0001 
            &nbsp;&nbsp;
            
          </h4>
        </div>

        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<div id="project-2" class="section level2">
<h2>Project 2</h2>
<p><em>Syed Kamil Riaz - skr973</em></p>
</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<pre class="r"><code>library(fivethirtyeight)
data(&quot;fifa_audience&quot;)
fifa &lt;- fifa_audience</code></pre>
<p>This dataset was brought to us by fivethirtyeight. In the dataset, the thing that was measured was FIFA audiences. There was 5 variables being show here with the first one being countries. This was followed by the categorical variable of Confederation. The confederation determiens what league you play soccer in and there are 6 possible categories for the confederation variable. The first numeric variable is Population share, which determines the number of people that a country has. The next two variables are also numeric and they are TV audience share and GDP weighted share. The TV audience share shows how many people had a TV in those repsective countries based on their total population. The final numeric variable showed GDP weighted average where the higher the number, the richer the respective country was. In this dataset, there are a total of 191 countries representing the number of observations in place.</p>
</div>
<div id="manova-assumption" class="section level1">
<h1>MANOVA assumption</h1>
<pre class="r"><code>library(rstatix)
fifa &lt;- manova(cbind(population_share, tv_audience_share, gdp_weighted_share)~confederation, data=fifa_audience)
summary(fifa)</code></pre>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## confederation 5 0.15835 2.0618 15 555 0.01041 *
## Residuals 185
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>#univariate ANOVA
summary.aov(fifa)</code></pre>
<pre><code>## Response population_share :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## confederation 5 41.48 8.2965 2.2287 0.05324 .
## Residuals 185 688.67 3.7225
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response tv_audience_share :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## confederation 5 26.67 5.3333 2.6484 0.02441 *
## Residuals 185 372.55 2.0138
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response gdp_weighted_share :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## confederation 5 23.62 4.7249 2.3 0.04671 *
## Residuals 185 380.05 2.0543
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>fifa_audience%&gt;%group_by(confederation)%&gt;%summarize(mean(population_share), mean(tv_audience_share), mean(gdp_weighted_share))</code></pre>
<pre><code>## # A tibble: 6 x 4
## confederation `mean(population_share)`
`mean(tv_audience_share)` `mean(gdp_weighted_share)`
## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 AFC 1.37 0.991 0.735
## 2 CAF 0.298 0.172 0.052
## 3 CONCACAF 0.26 0.327 0.527
## 4 CONMEBOL 0.560 1.35 1.03
## 5 OFC 0.0167 0.0167 0.00833
## 6 UEFA 0.270 0.548 0.848</code></pre>
<pre class="r"><code>#Post-hoc t tests
pairwise.t.test(fifa_audience$population_share, fifa_audience$confederation, p.adj=&quot;none&quot;)</code></pre>
<pre><code>##
## Pairwise comparisons using t tests with pooled SD
##
## data: fifa_audience$population_share and
fifa_audience$confederation
##
## AFC CAF CONCACAF CONMEBOL OFC
## CAF 0.0082 - - - -
## CONCACAF 0.0166 0.9321 - - -
## CONMEBOL 0.2334 0.6955 0.6707 - -
## OFC 0.0330 0.6506 0.7124 0.5116 -
## UEFA 0.0078 0.9426 0.9832 0.6667 0.6864
##
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(fifa_audience$tv_audience_share, fifa_audience$confederation, p.adj=&quot;none&quot;)</code></pre>
<pre><code>##
## Pairwise comparisons using t tests with pooled SD
##
## data: fifa_audience$tv_audience_share and
fifa_audience$confederation
##
## AFC CAF CONCACAF CONMEBOL OFC
## CAF 0.0061 - - - -
## CONCACAF 0.0507 0.6375 - - -
## CONMEBOL 0.4717 0.0176 0.0498 - -
## OFC 0.0369 0.7339 0.5233 0.0295 -
## UEFA 0.1429 0.1965 0.5075 0.1069 0.2497
##
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(fifa_audience$gdp_weighted_share, fifa_audience$confederation, p.adj=&quot;none&quot;)</code></pre>
<pre><code>##
## Pairwise comparisons using t tests with pooled SD
##
## data: fifa_audience$gdp_weighted_share and
fifa_audience$confederation
##
## AFC CAF CONCACAF CONMEBOL OFC
## CAF 0.0231 - - - -
## CONCACAF 0.5422 0.1533 - - -
## CONMEBOL 0.5583 0.0504 0.3374 - -
## OFC 0.1222 0.9246 0.2911 0.0976 -
## UEFA 0.7107 0.0072 0.3409 0.7161 0.0724
##
## P value adjustment method: none</code></pre>
<pre class="r"><code>#Type 1 error chance
1-0.95^5</code></pre>
<pre><code>## [1] 0.2262191</code></pre>
<pre class="r"><code>#Bonferroni Correction
.05/5</code></pre>
<pre><code>## [1] 0.01</code></pre>
<pre class="r"><code>#MANOVA assumptions
fifa1 &lt;- fifa_audience%&gt;%select(confederation, population_share, tv_audience_share, gdp_weighted_share)

ggplot(fifa1, aes(x = population_share, y = tv_audience_share)) +
 geom_point(alpha = .5) + geom_density_2d(h=2) + coord_fixed() + facet_wrap(~confederation)</code></pre>
<p><img src="/project/project2_files/figure-html/MANOVA-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>covmats&lt;-fifa1%&gt;%group_by(confederation)%&gt;%do(covs=cov(.[2:4]))
for(i in 1:4){print(covmats$covs[i])}</code></pre>
<pre><code>## [[1]]
## population_share tv_audience_share gdp_weighted_share
## population_share 15.357398 7.364712 3.388223
## tv_audience_share 7.364712 6.394197 3.696999
## gdp_weighted_share 3.388223 3.696999 3.279468
##
## [[1]]
## population_share tv_audience_share gdp_weighted_share
## population_share 0.16550612 0.1411673 0.04459592
## tv_audience_share 0.14116735 0.1743020 0.06168980
## gdp_weighted_share 0.04459592 0.0616898 0.02785306
##
## [[1]]
## population_share tv_audience_share gdp_weighted_share
## population_share 0.7417931 0.7831724 1.785931
## tv_audience_share 0.7831724 0.9020230 1.808920
## gdp_weighted_share 1.7859310 1.8089195 4.388920
##
## [[1]]
## population_share tv_audience_share gdp_weighted_share
## population_share 0.6693333 1.707778 1.301333
## tv_audience_share 1.7077778 4.367222 3.337222
## gdp_weighted_share 1.3013333 3.337222 2.595667</code></pre>
<p>In this part of the Project, MANOVA testing was first performed to show that there was a mean difference across the groups. This can be seen as the table shows that none of the numbers were similar meaning there was a mean difference when comparing the categorical response variable to the three numeric variables that are being tested, population share, tv audience, and GDP. Univariate ANOVAs for the dependent variable was conducted as a follow up test to show there was a mean difference across groups. A post-hoc t test was then performed three times to show that each of the groups did differ. The number of tests performed was 5 (1 MANOVA, 1 ANOVA, and 3 t tests), and was factored in while calculating a type I error wheer the result came out to be 0.2262191. After conducting the Type I error chance, the Bonferroni correction was then calculated to adjust for the chance of a type I error affecting the significant difference. The Bonferroni correction changed the alpha value from .05 to be .01. After calculating for the Bonferroni correction it can be seen that none of the values were significant for the most part. The final part here tested whether the MANOVA assumptions were met. The MANOVA assumptions are quite complicated as they require random samples, independent observations for starters which this dataset did meet. Other assumptions however were not able to be met as multivariate normality could not produce a working solution as can be seen in the plot showing that MANOVA assumptions were not met with this dataset. Since there are so many assumptions for MANOVA, and one of the first ones already failed, it is safe to say that MANOVA assumptions were not met for the Fifa Audience dataset.</p>
</div>
<div id="randomization-test" class="section level1">
<h1>Randomization Test</h1>
<pre class="r"><code>obs_F&lt;-2.287 #this is our observed F-statistic
Fs&lt;-replicate(5000,{ #do everything in curly braces 5000 times and save the output
new&lt;-fifa_audience%&gt;%mutate(confederation=sample(confederation)) #randomly permute response variable (confederation)
#compute the F-statistic by hand
SSW&lt;- new%&gt;%group_by(confederation)%&gt;%summarize(SSW=sum((population_share-mean(population_share))^2))%&gt;%
summarize(sum(SSW))%&gt;%pull
SSB&lt;- new%&gt;%mutate(mean=mean(population_share))%&gt;%group_by(confederation)%&gt;%mutate(groupmean=mean(population_share))%&gt;%
summarize(SSB=sum((mean-groupmean)^2))%&gt;%summarize(sum(SSB))%&gt;%pull
(SSB/5)/(SSW/186) #compute F statistic (num df = K-1 = 6-1, denom df = N-K = 191-5)
})
{hist(Fs,prob = T); abline(v=obs_F, col=&quot;blue&quot;, add=T)}</code></pre>
<p><img src="/project/project2_files/figure-html/Randomization%20Test-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>mean(Fs&gt;obs_F)</code></pre>
<pre><code>## [1] 0.0484</code></pre>
<p>Here we calculated an F statistic: <em>Null Hypothesis</em>:The centroid as well as the dispersion of the groups as defined by the measured space are equivalent for population share, tv audience share, and gdp weighted share. <em>Alternative Hypothesis</em>: The centroid and/or the spread of the objects is different between the population share, tv audience share, and gdp weighted share. <em>Results</em>: The p value is .0504 which is slighty greater than the alpha value of .05, which mean we fail to reject the null hypothesis. This means that the values should be equivalent for population share, tv audience share, and gdp weighted share.</p>
</div>
<div id="linear-regression-model" class="section level1">
<h1>Linear Regression Model</h1>
<pre class="r"><code>library(tidyverse)
#Mean centering and dummy coding variables
fifa1 &lt;- fifa_audience %&gt;%mutate(confed=ifelse(confederation==&quot;AFC&quot;,1,0))
fifa1 &lt;- fifa1%&gt;%mutate(PopShare_c = population_share - mean(population_share, na.rm = T))
fifa1 &lt;- fifa1%&gt;%mutate(TVAud_c = tv_audience_share - mean(tv_audience_share, na.rm = T))
fifa1 &lt;- fifa1%&gt;%mutate(GDP_c = gdp_weighted_share - mean(gdp_weighted_share, na.rm = T))

#Linear regression model
linfit &lt;- lm(GDP_c~TVAud_c*PopShare_c, data = fifa1)
summary(linfit)</code></pre>
<pre><code>##
## Call:
## lm(formula = GDP_c ~ TVAud_c * PopShare_c, data = fifa1)
##
## Residuals:
## Min 1Q Median 3Q Max
## -4.2377 -0.1004 0.0191 0.0195 6.8882
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.074060 0.059895 1.236 0.218
## TVAud_c 1.176741 0.068244 17.243 &lt; 2e-16 ***
## PopShare_c -0.022359 0.050672 -0.441 0.660
## TVAud_c:PopShare_c -0.035826 0.005456 -6.567 4.94e-10
***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 0.813 on 187 degrees of freedom
## Multiple R-squared: 0.6938, Adjusted R-squared: 0.6889
## F-statistic: 141.3 on 3 and 187 DF, p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>#plot of regression
ggplot(fifa1, aes(x = GDP_c, y = TVAud_c, group = confederation)) + 
  geom_point(aes(color=confederation)) +
  geom_smooth(method=&quot;lm&quot;, se=F,fullrange=T,aes(color=confederation))+
theme(legend.position=c(.15,.85), legend.title = element_text(size=10), legend.text = element_text(size=5))</code></pre>
<p><img src="/project/project2_files/figure-html/Linear%20Regression%20Model-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#Checking assumptions
resid&lt;-linfit$residuals
fit&lt;-linfit$fitted.values
ggplot()+geom_point(aes(fit,resid))+geom_hline(yintercept=0, color=&#39;green&#39;)</code></pre>
<p><img src="/project/project2_files/figure-html/Linear%20Regression%20Model-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot()+geom_histogram(aes(resid), bins=75)</code></pre>
<p><img src="/project/project2_files/figure-html/Linear%20Regression%20Model-3.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot()+geom_qq(aes(sample=resid))+geom_qq_line(aes(sample=resid, color=&#39;blue&#39;)) + theme(legend.position = &quot;none&quot;)</code></pre>
<p><img src="/project/project2_files/figure-html/Linear%20Regression%20Model-4.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#normal standard error
library(dplyr)
library(sandwich)
library(lmtest)
library(tidyverse)
library(plotROC)
library(pROC)
coeftest(linfit)</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.0740604 0.0598953 1.2365 0.2178
## TVAud_c 1.1767412 0.0682444 17.2431 &lt; 2.2e-16 ***
## PopShare_c -0.0223589 0.0506717 -0.4413 0.6595
## TVAud_c:PopShare_c -0.0358259 0.0054558 -6.5666
4.944e-10 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>#robust standard error
coeftest(linfit, vcov=vcovHC(linfit))</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.074060 0.120749 0.6133 0.5403944
## TVAud_c 1.176741 0.321570 3.6594 0.0003288 ***
## PopShare_c -0.022359 0.375590 -0.0595 0.9525934
## TVAud_c:PopShare_c -0.035826 0.040645 -0.8814 0.3792173
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>#Regression without interactions and likelihood ratio test
linfit2 &lt;- lm(GDP_c~TVAud_c+GDP_c, data = fifa1)
summary(linfit2)</code></pre>
<pre><code>##
## Call:
## lm(formula = GDP_c ~ TVAud_c + GDP_c, data = fifa1)
##
## Residuals:
## Min 1Q Median 3Q Max
## -4.2860 -0.1925 -0.1150 -0.0925 7.8522
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 7.107e-15 6.737e-02 0.00 1
## TVAud_c 7.751e-01 4.660e-02 16.63 &lt;2e-16 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 0.9311 on 189 degrees of
freedom
## Multiple R-squared: 0.5941, Adjusted R-squared: 0.592
## F-statistic: 276.6 on 1 and 189 DF, p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>lrtest(linfit, linfit2)</code></pre>
<pre><code>## Likelihood ratio test
##
## Model 1: GDP_c ~ TVAud_c * PopShare_c
## Model 2: GDP_c ~ TVAud_c + GDP_c
## #Df LogLik Df Chisq Pr(&gt;Chisq)
## 1 5 -229.44
## 2 3 -256.38 -2 53.859 2.017e-12 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<p>The first thing that was done as part of this section was to mean to dummy code for one of the Confederations (AFC) for later study in this section as well as to mean center the three numeric variables. As part of this linear regression model the thing that was decided upon to study was the various confederations against one another. &quot;AFC&quot; represents the confederation of teams in Asia. &quot;UEFA&quot; is European teams. &quot;CONCAF&quot; is North American and LAtin American teams. &quot;CONMEBOL&quot; is South American teams. &quot;OFC&quot; is oceanic nations, and finally &quot;CAF&quot; are African nation. Here their GDP and TV Audience was compared as part of this regression model. One can see from the first plot, that surprisingly African countries which tend to have a higher GDP tend to have a slighty higher audience share as well, with soccer being the least popular in North America. By looking at the coefficients and trying to interpret them for the first linear fit line, it can be seen that for nations that Asian countries tend to have a starting GDP factored to be around 0.074 higher when factoring in TV Audience and population share. This simply means that on average Asian countries are richer than other countries that play soccer. Another interpretation that can be taken away from the coefficients is that when controlling for population share, Asian countries tend to have a much higher number of TVs at about 1.177 more for every increase in population share. This means that Asian countries not only lead in the total GDP in the world for soccer playing nations, but they also tend to have the most TVs watching them play as well. However, there is no significant difference between the number of TVs in a country and the population of a country. The main significance of the results is approximately the same even after recomputing with the robust SEs. There wasn’t a big difference or change between any of the original SEs and the the robust SEs which makes sense as to why the significance of the results didn’t vary. There were not many changes but there were enoguh to increase teh % variation in the outcome, which can be seen with the variables. When the SEs decreases, t value increases, and p value decreases which the model shows. Also depicted in the model is a 59.2% (using the adjusted R^2 value) of the variation in the outcome.</p>
</div>
<div id="bootstrapped-standard-errors" class="section level1">
<h1>Bootstrapped standard errors</h1>
<pre class="r"><code>samp_distn&lt;-replicate(5000, {
 boot_dat&lt;-boot_dat&lt;-fifa1[sample(nrow(fifa1),replace=TRUE),]
 bootfit&lt;-lm(GDP_c~TVAud_c*PopShare_c, data = boot_dat)
 coef(bootfit)
})

samp_distn%&gt;%t%&gt;%as.data.frame%&gt;%summarize_all(sd)</code></pre>
<pre><code>##   (Intercept)   TVAud_c PopShare_c TVAud_c:PopShare_c
## 1     0.12909 0.2976308  0.3853424          0.1418718</code></pre>
<p>When SE tends to increase, the t value decreased which causes the p value to increase. By interpreting, one can see that the bootstrapped SE for the intercept is greater than both the original and robust SE values. This in turn means that the t value for it is less and as a result this causes the p value to be larger for the intercept. The bootstrapped SEs for the TVAud_c are greater than the original, but less than the robust SEs, meaning that when compared to the t and p values of the original SEs, the bootstrapped t values will be less, while the p values will be larger. In comparison with the robust SEs t and p values, the bootstrapped values will be greater and the p values will be lesser. Both the PopShare_c and the PopShare_c:HeartRate_c, values are greater than the original SEs and the Robust, meaning that the t value for it is less and as a result this causes the p value to be larger for these SEs.</p>
</div>
<div id="logistic-regression" class="section level1">
<h1>Logistic Regression</h1>
<pre class="r"><code>library(dplyr)
library(sandwich)
library(lmtest)
library(tidyverse)
#Logistic regression
logfit&lt;-glm(confed~population_share + tv_audience_share+gdp_weighted_share, data=fifa1, family=&quot;binomial&quot;)
coeftest(logfit)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -1.50959 0.20831 -7.2470 4.262e-13 ***
## population_share 0.95880 0.45378 2.1129 0.03461 *
## tv_audience_share -0.01018 0.32115 -0.0317 0.97471
## gdp_weighted_share -0.25838 0.21265 -1.2151 0.22435
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>exp(coef(logfit))%&gt;%data.frame()</code></pre>
<pre><code>##                            .
## (Intercept)        0.2210006
## population_share   2.6085588
## tv_audience_share  0.9898716
## gdp_weighted_share 0.7722991</code></pre>
<pre class="r"><code>#ConfusionMatrix
prob &lt;- predict(logfit, type=&quot;response&quot;)
table(truth=fifa1$confed,predict=as.numeric(prob&gt;.5))%&gt;%addmargins</code></pre>
<pre><code>##      predict
## truth   0   1 Sum
##   0   147   1 148
##   1    38   5  43
##   Sum 185   6 191</code></pre>
<pre class="r"><code>#Accuracy
(147+5)/191</code></pre>
<pre><code>## [1] 0.7958115</code></pre>
<pre class="r"><code>#Sensitivity (TPR)
5/191</code></pre>
<pre><code>## [1] 0.02617801</code></pre>
<pre class="r"><code>#Specificity (TNR)
147/148</code></pre>
<pre><code>## [1] 0.9932432</code></pre>
<pre class="r"><code>#Recall/Precision (PPV)
5/6</code></pre>
<pre><code>## [1] 0.8333333</code></pre>
<pre class="r"><code>#Density of log-odds plot
Logfifa1 &lt;- fifa1
Logfifa1$logit &lt;- predict(logfit)
ggplot(Logfifa1, aes(logit, fill=confederation)) + geom_density(alpha=0.3) + geom_vline(xintercept=0, lty=2)</code></pre>
<p><img src="/project/project2_files/figure-html/Logistic%20Regression-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#ROC curve and AUC
Rocfifa &lt;- fifa1%&gt;%mutate(probability=predict(logfit, type = &quot;response&quot;), prediction=ifelse(prob&gt;.5,1,0))

classify&lt;-Rocfifa%&gt;%transmute(probability,prediction,truth=confed)
library(tidyverse)
library(plotROC)
library(dbplyr)
ROCplot&lt;-ggplot(classify)+ geom_roc(aes(d=truth,m=probability), n.cuts=0) + geom_segment(aes(x=0,y=0,xend=1,yend=1),lty=2)
ROCplot</code></pre>
<p><img src="/project/project2_files/figure-html/Logistic%20Regression-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.6067725</code></pre>
<p>Here the coefficient estimates are first shown. The intercept coeffiecient which means that when there a 0 population share, a 0 TV audience share, and 0 GDP, it shows there is a -1.5 meaning there is no estimate at that place. The most useful data that can be taken from the coefficent estimates are through looking at the population share estimates where if you control for TV audience, and GDP it still shows the average population of the country to be 0.9588. The next step that was done was to run a confusion matrix. The confusion matrix allowed us to better run our statistics and showed that the accuracy was 79.6% while the sensitivity was only 2.6%. The specificity was at 99.3% and the precision is at 83.33%. A ggplot was then calculated in order to show they different colored grouping of the different confederations, before a ROC curve was used to further show statistics. The ROC curve pictured above lso was not a straight line indicating that it might be possible to distinguish the positive and negative parts of the graph. The last thing that was conducted here was calculating the AUC through the use of a package. THe AUC here was 0.606 and that shows it is a fair indicator of the new data.</p>
<pre class="r"><code>#10-fold CV
set.seed(1234)
k=10
class_diag&lt;-function(probs,truth){
  
  tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
  
  #how to calculate AUC
  ord&lt;-order(probs, decreasing=TRUE)
  probs &lt;- probs[ord]; truth &lt;- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
  TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
  
  n &lt;- length(TPR)
  auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}
data&lt;-fifa1[sample(nrow(fifa1)),]
folds&lt;-cut(seq(1:nrow(fifa1)),breaks=k,labels=F)

diags&lt;-NULL
for(i in 1:k){
 train&lt;-data[folds!=i,]
 test&lt;-data[folds==i,]
 truth&lt;-test$confed
 train_fit&lt;-glm(confed~ population_share + tv_audience_share + gdp_weighted_share, data=train,family=&quot;binomial&quot;)
 probs&lt;-predict(train_fit,newdata = test,type=&quot;response&quot;)
 diags&lt;-rbind(diags,class_diag(probs,truth))
}
apply(diags, 2, mean, na.rm = TRUE)</code></pre>
<pre><code>##       acc      sens      spec       ppv       auc 
## 0.7907895 0.1116667 0.9878676 0.6000000 0.5789266</code></pre>
<pre class="r"><code>#Lasso Regression
lassofit &lt;- glm(confed ~ -1 + population_share + tv_audience_share + gdp_weighted_share, data = fifa1, family = &quot;binomial&quot;)
library(glmnet)
library(dplyr)
library(sandwich)
library(lmtest)
library(tidyverse)
y&lt;-as.matrix(fifa1$confed)
x&lt;-model.matrix(lassofit)
x&lt;-scale(x)
cv&lt;-cv.glmnet(x,y, family=&#39;binomial&#39;)
lasso&lt;-glmnet(x,y,family=&quot;binomial&quot;,lambda=cv$lambda.1se)
coef(cv)</code></pre>
<pre><code>## 4 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                            1
## (Intercept)        -1.236012
## population_share    .       
## tv_audience_share   .       
## gdp_weighted_share  .</code></pre>
<pre class="r"><code>prob1 &lt;- predict(lassofit, type=&quot;response&quot;)

class_diag(prob1, fifa1$confed)</code></pre>
<pre><code>##         acc      sens      spec       ppv       auc
## 1 0.6335079 0.4186047 0.6959459 0.2857143 0.5266342</code></pre>
<pre class="r"><code>#10-fold CV again
set.seed(1234)
k=10

data2&lt;-fifa1[sample(nrow(fifa1)),]
folds2&lt;-cut(seq(1:nrow(fifa1)),breaks=k,labels=F)

diags2&lt;-NULL
for(i in 1:k){
 train2&lt;-data2[folds!=i,]
 test2&lt;-data2[folds==i,]
 truth2&lt;-test2$confed
 train_fit2&lt;-glm(confed~ population_share, data=train2, family=&quot;binomial&quot;)
 probs2&lt;-predict(train_fit2,newdata = test2,type=&quot;response&quot;)
 diags2&lt;-rbind(diags2,class_diag(probs2,truth2))
}

apply(diags2, 2, mean, na.rm = TRUE)</code></pre>
<pre><code>##        acc       sens       spec        ppv        auc 
## 0.78552632 0.05833333 0.99375000 0.66666667 0.63551649</code></pre>
<p>The first thing that was done here was to look at the the first 10 fold which allowed us to see the first value given accuracy which was 79.08%. This meant that model correctly predicts 79.08% of the outcomes in the total data. The sensitivity tells me that 11.17% out of the total number of cases are positive. In terms of the number of correctly predicted negative cases, 98.89% is that percentage. The PPV number says how many positives are correct and true positives and here that number is simply 60%. The AUC number here is 0.5789 which is a little lower than the AUC we previously predicted. In comparison with the classification diagnostics in the in-sample metrics the accuracy, senesitivity, and the specificity were also so similar no distinction could even be made, but precision was certainly lwoere her at 60% then it was before at at 83%. Next, the lasso regression was performed in order to determine which model had the best accuracy. If the model were correctly and there was an actually accurate or correlated data one or a few of the explanatory variables would have been selected for. However, this was certainly not the case for my janky data. There were no varibales retained, but the data and 10 fold still had to go on. So I decided to pick up the poulation_share and treat it as if the lasso regression selected that example. The 10 fold CV test was performed using the fake selected variable and a model sample of AUC was created which could be compared to my logistic regression AUC. THe values for the lasso regression were 0.78552632 0.05833333 0.99375000 0.66666667 0.63551649 representing accuracy, sensitivity, specificity, precision, and AUC respectively. Compared to the logistic regression above which had values of 0.7907895 0.1116667 0.9878676 0.6000000 0.5789266. The most important values to compare are the accuracy which has slightly increased in the LASSO regression model and the AUC which has actually decreased. If there was actaully a variable picked by lasso and not one done at random, like what was conducted here, the AUC should have gone up with LASSO regression as it shows that using signifcant variables will help improve prediction.</p>
</div>

            
        <hr>         <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div> 
            </div>
          </div>

   <hr>  <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div> 
        </div>
      </div>
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with ♥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="/js/docs.min.js"></script>
<script src="/js/main.js"></script>

<script src="/js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
